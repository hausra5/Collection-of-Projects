{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filtering with Naive Bayes\n",
    "In this project, we will be constructing a spam filtering program that uses multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages which has been classified by humans.  \n",
    "\n",
    "When looking at the steps a computer will take to classify incoming new messages as spam, the steps taken are pretty simiple.  They consist of:\n",
    "\n",
    "- Learning how humans classify messages\n",
    "\n",
    "- Use the human knowledge to estimate probabilities for new messages (spam vs non-spam)\n",
    "\n",
    "- Based on which has a higher probability (spam vs non-spam), the computer will classify the new message as spam or non-spam.\n",
    "\n",
    "Using the dataset put together by Tiago A. Almeida and Jose Maria Gomez Hidalgo, we'll help the computer learn to classify spam vs non spam.  We'll need to split the data into training and testing sets.  This way after we train the algorithm on the training set, we can then run the model on the test set to predit the classifications.  Hopefully, if the model is succesful, using the simple Naive Bayes algorithm, we'll be able to classify incoming messages with high accuracy.  Ideally we'd like to exceed 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data\n",
    "We'll first want to import the data and get familiarized with it.  The data is tab separated and has no headers, so we'll need to update the read parameters to account for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sms = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names = ['Label','SMS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks organized correctly and has about 86% regular messages.  This seems pretty accurate as most e-mails people get will be non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Sets\n",
    "In order for our algorithm to gain higher accuracy, we'll want to train the algorithm on part of the data and then test the algorithm on a different part.  This way as the alogorithm learns, we can test the accuracy.  For this dataset, we'll split the data as following:\n",
    "\n",
    "- Training set will have 4,458 messages (80%)\n",
    "\n",
    "- Test set will have 1,114 messages (20%)\n",
    "\n",
    "We'll want to first randomize all the data and then use the <code>random_state</code> parameter to make sure our results our reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (4458, 2)\n",
      "Test:  (1114, 2)\n"
     ]
    }
   ],
   "source": [
    "#randomize the data\n",
    "random_sms = sms.sample(frac=1,random_state=1)\n",
    "\n",
    "#80/20 split index\n",
    "training_split = round(len(random_sms) *.80)\n",
    "\n",
    "#split the data\n",
    "train_sms = random_sms[:training_split].reset_index(drop=True)\n",
    "test_sms = random_sms[training_split:].reset_index(drop=True)\n",
    "\n",
    "print('Train: ',train_sms.shape)\n",
    "print('Test: ',test_sms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sms['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sms['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the test and training set have approximately the same breakdown of spam vs non spam.  They also both match the original dataset breakdown.  That means we're good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Now that we have our Training and Test sets, before we beging caluclating probabilities and applying the Naive Bayes algorithm, we'll first need to clean the data.\n",
    "\n",
    "We'll want to make sure our message vocabulary is consistent, so we'll bring everything down to lowercase and we'll remove punctuation.  \n",
    "\n",
    "Ultimately, we'll want to have each row contain counters of the words used in each message in our training set.  For example, the message \"SECRET PRIZE! CLAIM SECRET PRIZE NOW!!\", will be converted to counters.  We want our new data set to look like the following:\n",
    "\n",
    "| Label | secret | prize | claim | now | coming | to | my | party | winner |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| spam | 2 | 2 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| ham | 1 | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 0 |\n",
    "| spam | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 1 |\n",
    "\n",
    "Let's begin by removing punctuation and lowercasing the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sms['SMS'] = train_sms['SMS'].str.replace('\\W',' ').str.lower()\n",
    "train_sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a vocabulary list\n",
    "Now that we have the SMS messages cleaned, we need to put together a master list of each word used.  We'll iterate over each word and add it to a list.  We'll then transform the list into a set which will remove duplicates and then bring it back to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary words:  7783\n"
     ]
    }
   ],
   "source": [
    "#split the sms column\n",
    "train_sms['SMS'] = train_sms['SMS'].str.split()\n",
    "vocab_list = []\n",
    "for message in train_sms['SMS']:\n",
    "    for word in message:\n",
    "        vocab_list.append(word)\n",
    "\n",
    "vocab = list(set(vocab_list))\n",
    "print('Total vocabulary words: ',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a total of 7783 unique words used in all of the training SMS messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Training Set\n",
    "Now that we have the vocabulary list we can now create our final training dataset that will have vocabulary counts for each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deluxe</th>\n",
       "      <th>hugs</th>\n",
       "      <th>hits</th>\n",
       "      <th>pillows</th>\n",
       "      <th>ls15hb</th>\n",
       "      <th>failing</th>\n",
       "      <th>hrs</th>\n",
       "      <th>smidgin</th>\n",
       "      <th>careless</th>\n",
       "      <th>visa</th>\n",
       "      <th>...</th>\n",
       "      <th>wotu</th>\n",
       "      <th>gautham</th>\n",
       "      <th>afraid</th>\n",
       "      <th>447801259231</th>\n",
       "      <th>okey</th>\n",
       "      <th>inconsiderate</th>\n",
       "      <th>trivia</th>\n",
       "      <th>pretend</th>\n",
       "      <th>do</th>\n",
       "      <th>leftovers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   deluxe  hugs  hits  pillows  ls15hb  failing  hrs  smidgin  careless  visa  \\\n",
       "0       0     0     0        0       0        0    0        0         0     0   \n",
       "1       0     0     0        0       0        0    0        0         0     0   \n",
       "2       0     0     0        0       0        0    0        0         0     0   \n",
       "3       0     0     0        0       0        0    0        0         0     0   \n",
       "4       0     0     0        0       0        0    0        0         0     0   \n",
       "\n",
       "   ...  wotu  gautham  afraid  447801259231  okey  inconsiderate  trivia  \\\n",
       "0  ...     0        0       0             0     0              0       0   \n",
       "1  ...     0        0       0             0     0              0       0   \n",
       "2  ...     0        0       0             0     0              0       0   \n",
       "3  ...     0        0       0             0     0              0       0   \n",
       "4  ...     0        0       0             0     0              0       0   \n",
       "\n",
       "   pretend  do  leftovers  \n",
       "0        0   0          0  \n",
       "1        0   0          0  \n",
       "2        0   0          0  \n",
       "3        0   0          0  \n",
       "4        0   0          0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the unique word dictionary\n",
    "word_counts_per_sms = {unique_word: [0] * len(train_sms['SMS']) for \n",
    "                      unique_word in vocab}\n",
    "#Count each word\n",
    "for index,sms in enumerate(train_sms['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset made with the vocab list count, we can combine it with our original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>deluxe</th>\n",
       "      <th>hugs</th>\n",
       "      <th>hits</th>\n",
       "      <th>pillows</th>\n",
       "      <th>ls15hb</th>\n",
       "      <th>failing</th>\n",
       "      <th>hrs</th>\n",
       "      <th>smidgin</th>\n",
       "      <th>...</th>\n",
       "      <th>wotu</th>\n",
       "      <th>gautham</th>\n",
       "      <th>afraid</th>\n",
       "      <th>447801259231</th>\n",
       "      <th>okey</th>\n",
       "      <th>inconsiderate</th>\n",
       "      <th>trivia</th>\n",
       "      <th>pretend</th>\n",
       "      <th>do</th>\n",
       "      <th>leftovers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  deluxe  hugs  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0     0   \n",
       "2   ham                    [welp, apparently, he, retired]       0     0   \n",
       "3   ham                                           [havent]       0     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0     0   \n",
       "\n",
       "   hits  pillows  ls15hb  failing  hrs  smidgin  ...  wotu  gautham  afraid  \\\n",
       "0     0        0       0        0    0        0  ...     0        0       0   \n",
       "1     0        0       0        0    0        0  ...     0        0       0   \n",
       "2     0        0       0        0    0        0  ...     0        0       0   \n",
       "3     0        0       0        0    0        0  ...     0        0       0   \n",
       "4     0        0       0        0    0        0  ...     0        0       0   \n",
       "\n",
       "   447801259231  okey  inconsiderate  trivia  pretend  do  leftovers  \n",
       "0             0     0              0       0        0   0          0  \n",
       "1             0     0              0       0        0   0          0  \n",
       "2             0     0              0       0        0   0          0  \n",
       "3             0     0              0       0        0   0          0  \n",
       "4             0     0              0       0        0   0          0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sms_clean = pd.concat([train_sms,word_counts],axis=1)\n",
    "train_sms_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Constants\n",
    "Now that we have the dataset clean, we'll have to use the following probability equations to create our spam filter.\n",
    "\n",
    "These are the equations we'll need to solve for to properly implement the Naive Bayes Algorithm:\n",
    "\n",
    "-----------------------\n",
    "\n",
    "$$P(Spam|w_1,w_2,...,w_n) = P(Spam)\\cdot\\prod_{i=1}^{n}P(w_i|Spam)$$ \n",
    "\n",
    "$$P(Non Spam|w_1,w_2,...,w_n) = P(Non Spam)\\cdot\\prod_{i=1}^{n}P(w_i|NonSpam)$$ \n",
    "\n",
    "-----------------------\n",
    "\n",
    "$$P(w_i|Spam) = \\frac{(N_{wi|Spam} + \\alpha)}{(N_{Spam} + {\\alpha}\\cdot{N_{Vocab}})}$$\n",
    "\n",
    "$$P(w_i|Non Spam) = \\frac{(N_{wi|NonSpam} + \\alpha)}{(N_{Non Spam} + {\\alpha}\\cdot{N_{Vocab}})}$$\n",
    "\n",
    "-----------------------\n",
    "\n",
    "First, we'll need to calculate the constants for those equations.  So we'll begin by calculating the following:\n",
    "- $P(Spam)$ and $P(NonSpam)$\n",
    "- $N_{spam}, N_{nonSpam}, N_{vocab}$\n",
    "\n",
    "We need to keep in mind that the following holds true:\n",
    "- $N_{spam}$ is equal to the number of words in all spam messages (not equal to number of spam messages and not equal to total number of unique words in spam messages).\n",
    "\n",
    "- $N_{NonSpam}$ is equal to the number of words in all non-spam messages (not equal to number of non-spam messages and not equal to total number of unique words in non-spam messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter based on label\n",
    "spam_sms = train_sms_clean[train_sms_clean['Label'] == 'spam']\n",
    "non_spam_sms = train_sms_clean[train_sms_clean['Label'] == 'ham']\n",
    "\n",
    "#basic probability of spam vs non spam\n",
    "p_spam = len(spam_sms) / len(train_sms_clean)\n",
    "p_non_spam = len(non_spam_sms) / len(train_sms_clean)\n",
    "\n",
    "#calculate all words used in spam messages\n",
    "n_spam = spam_sms['SMS'].apply(len).sum()\n",
    "\n",
    "#calculate all words used in non spam messages\n",
    "n_non_spam = non_spam_sms['SMS'].apply(len).sum()\n",
    "\n",
    "#calculate all words used in vocabulary\n",
    "n_vocab = len(vocab)\n",
    "\n",
    "#set alpha parameter for Laplace smoothing to 1\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating all parameters\n",
    "Now that we have the constants set, we'll want to calculate the parameters of each word is classified as spam or not spam.\n",
    "\n",
    "We'll do this by first calculating the parameters of both with the following equations.\n",
    "\n",
    "$$P(w_i|Spam) = \\frac{(N_{wi|Spam} + \\alpha)}{(N_{Spam} + {\\alpha}\\cdot{N_{Vocab}})}$$\n",
    "\n",
    "$$P(w_i|Non Spam) = \\frac{(N_{wi|NonSpam} + \\alpha)}{(N_{Non Spam} + {\\alpha}\\cdot{N_{Vocab}})}$$\n",
    "\n",
    "Calculating all of the parameters beforehand will help speed up our classifier when testing and in a real world situation.  Rather than having each calculation done when a new message arrives, it will already be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize both dictionaries\n",
    "spam_parameters = {unique_word:0 for unique_word in vocab}\n",
    "non_spam_parameters = {unique_word:0 for unique_word in vocab}\n",
    "\n",
    "#calculate probabilities\n",
    "for word in vocab:\n",
    "    n_word_given_spam = spam_sms[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocab)\n",
    "    spam_parameters[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_non_spam = non_spam_sms[word].sum()\n",
    "    p_word_given_non_spam = (n_word_given_non_spam + alpha) / (n_non_spam + alpha*n_vocab)\n",
    "    non_spam_parameters[word] = p_word_given_non_spam\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiying a new message\n",
    "Now that we have all of the parameters calculated, we can now begin creating our spam filter.  We'll want our function to do the following:\n",
    "\n",
    "- Takes in as input a new message ($w_1, w_2, ..., w_n$).\n",
    "- Calculates $P(Spam|w_1, w_2, ..., w_n)$ and $P(Non Spam|w_1, w_2, ..., w_n)$.\n",
    "- Compares the values of $P(Spam|w_1, w_2, ..., w_n)$ and $P(Non Spam|w_1, w_2, ..., w_n)$, and:\n",
    "    - If $P(Non Spam|w_1, w_2, ..., w_n) > P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as non spam.\n",
    "    - If $P(Non Spam|w_1, w_2, ..., w_n) < P(Spam|w_1, w_2, ..., w_n)$, then the message is classified as spam.\n",
    "    - If $P(Non Spam|w_1, w_2, ..., w_n) = P(Spam|w_1, w_2, ..., w_n)$, then the algorithm may request human help.\n",
    "    \n",
    "Here is where we will implment the Naive Bayes Algorithm.  Again, it is as follows:\n",
    "\n",
    "$$P(Spam|w_1,w_2,...,w_n) = P(Spam)\\cdot\\prod_{i=1}^{n}P(w_i|Spam)$$ \n",
    "\n",
    "$$P(Non Spam|w_1,w_2,...,w_n) = P(Non Spam)\\cdot\\prod_{i=1}^{n}P(w_i|NonSpam)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classify function\n",
    "import re\n",
    "def classify(message):\n",
    "    message = re.sub('\\W',' ',message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_non_spam_given_message = p_non_spam\n",
    "    \n",
    "    for word in message:  \n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "        \n",
    "        if word in non_spam_parameters:\n",
    "            p_non_spam_given_message *= non_spam_parameters[word]\n",
    "    \n",
    "    print('P(Spam|message): ',p_spam_given_message)\n",
    "    print('P(Non_Spam|message): ',p_non_spam_given_message)\n",
    "    \n",
    "    if p_non_spam_given_message > p_spam_given_message:\n",
    "        print('Label: Non Spam')\n",
    "    elif p_non_spam_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message):  1.3481290211300841e-25\n",
      "P(Non_Spam|message):  1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message):  2.4372375665888117e-25\n",
      "P(Non_Spam|message):  3.687530435009238e-21\n",
      "Label: Non Spam\n"
     ]
    }
   ],
   "source": [
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far it looks good.  Since we tuned our algorithm based on the training set, we can now test it on the test set to see how well our spam filter does at prediciting correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Accuracy on the test set\n",
    "Now we can update the classifier function a bit to return labels so we can create a new column in our test set that displays the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_non_spam_given_message = p_non_spam\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "\n",
    "        if word in non_spam_parameters:\n",
    "            p_non_spam_given_message *= non_spam_parameters[word]\n",
    "\n",
    "    if p_non_spam_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_non_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sms['predicted'] = test_sms['SMS'].apply(classify_test_set)\n",
    "test_sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly looking at the first 5, the predictions look like they are accurate.  Let's test the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  1100\n",
      "Incorrect:  14\n",
      "Accuracy:  0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_sms.shape[0]\n",
    "\n",
    "for row in test_sms.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "print('Correct: ', correct)\n",
    "print('Incorrect: ',total-correct)\n",
    "print('Accuracy: ',correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our spam filter worked extremely well.  It correctly classified 98.7% of all e-mails!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Accuracy\n",
    "Given that our model is pretty accurate, we could leave it as is, or we could investigate further to see if we can tweak it a bit to increase accuracy.  We can begin by looking at the misclassified messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "152   ham                  Unlimited texts. Limited minutes.   \n",
       "159   ham                                       26th OF JULY   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302   ham                   No calls..messages..missed calls   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      predicted  \n",
       "114                         ham  \n",
       "135                         ham  \n",
       "152                        spam  \n",
       "159                        spam  \n",
       "284                        spam  \n",
       "293  needs human classification  \n",
       "302                        spam  \n",
       "319                        spam  \n",
       "504                         ham  \n",
       "546                         ham  \n",
       "741                         ham  \n",
       "876                         ham  \n",
       "885                         ham  \n",
       "953                         ham  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sms[test_sms['Label'] != test_sms['predicted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that potentially words not in the vocabulary (ie. 146tf150p), general context of the message, or referencing phone related topics cause misclassifcations.  If we want, we can make our model a bit more robust by accounting for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Using a relatively simple algorithm, the Naive Bayes algorithm, we were able to build a very functional spam filtering program that was able to classify message with almost a 99% accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
